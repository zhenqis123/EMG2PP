_target_: emg2pose.networks.CausalTransformerAutoregressiveDecoder

# Token dimension. With TDS default (64 features) and `state_condition=True` (20 joints):
# token_dim = 64 + 20 = 84.
in_channels: 84

# Output dimension per step. For VEMG2Pose-style logic this should be 2 * pose_dim
# because it is split into (pos, vel).
out_channels: 40

# GPT2-style Transformer config
n_embd: 256
n_layer: 6
n_head: 8
n_positions: 1024

# Dropouts
embd_pdrop: 0.1
resid_pdrop: 0.1
attn_pdrop: 0.1

layer_norm_epsilon: 1e-5

# Optional scaling on the final projection (kept for parity with existing decoders).
output_scale: 0.01

# Enable KV-cache across autoregressive steps.
use_cache: True
