_target_: emg2pose.networks.RotaryCausalTransformerAutoregressiveDecoder

# Token dimension. With TDS default (64 features) and `state_condition=True` (20 joints):
# token_dim = 64 + 20 = 84.
in_channels: 84

# Output dimension per step. For VEMG2Pose-style logic this should be 2 * pose_dim
# because it is split into (pos, vel).
out_channels: 40

# GPTNeoX (RoPE) config
hidden_size: 256
intermediate_size: 1024
num_hidden_layers: 6
num_attention_heads: 8
max_position_embeddings: 2048
rotary_pct: 1.0
rotary_emb_base: 10_000

hidden_dropout: 0.1
attention_dropout: 0.1
layer_norm_eps: 1e-5

output_scale: 0.01
use_cache: True
